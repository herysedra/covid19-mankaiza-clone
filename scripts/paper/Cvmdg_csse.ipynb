{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cvmdg_csse.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMUT+F59oD6snCeFN7vNsaQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/herysedra/covid19-mankaiza-clone/blob/andrana/scripts/paper/Cvmdg_csse.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-PVvOUWhyBT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lq5j2J_oh_hC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats\n",
        "import matplotlib\n",
        "import pickle\n",
        "\n",
        "\n",
        "\n",
        "csse_confirmed_cases_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
        "csse_confirmed_cases = pd.read_csv(csse_confirmed_cases_url, sep=',')\n",
        "\n",
        "deaths_url =  'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv'\n",
        "deaths = pd.read_csv(deaths_url, sep=',')\n",
        "\n",
        "csse_recovered_cases_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv'\n",
        "csse_recovered_cases = pd.read_csv(csse_recovered_cases_url, sep=',')\n",
        "\n",
        "who_cases_mdg = pd.read_csv(\"/content/drive/My Drive/data/who mdg.csv\")\n",
        "\n",
        "cco_cases_mdg = pd.read_csv(\"/content/drive/My Drive/data/cco mdg.csv\")\n",
        "\n",
        "\n",
        "path_to_save = '/content/drive/My Drive/sary/'\n",
        "path_data = '/content/drive/My Drive/data/'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC3z-r-XiCFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def delay_cases(new_I_t, len_new_I_t, len_new_cases_obs , delay, delay_arr):\n",
        "\n",
        "\n",
        "    delay_mat = make_delay_matrix(n_rows=len_new_I_t, \n",
        "                                  n_columns=len_new_cases_obs, initial_delay=delay_arr)\n",
        "    inferred_cases = interpolate(new_I_t, delay, delay_mat)\n",
        "    return inferred_cases \n",
        "\n",
        "def make_delay_matrix(n_rows, n_columns, initial_delay=0):\n",
        "    \"\"\"\n",
        "    Has in each entry the delay between the input with size n_rows and the output\n",
        "    with size n_columns\n",
        "    \"\"\"\n",
        "    size = max(n_rows, n_columns)\n",
        "    mat = np.zeros((size, size))\n",
        "    for i in range(size):\n",
        "        diagonal = np.ones(size-i)*(initial_delay + i)\n",
        "        mat += np.diag(diagonal, i)\n",
        "    for i in range(1, size):\n",
        "        diagonal = np.ones(size-i)*(initial_delay - i)\n",
        "        mat += np.diag(diagonal, -i)\n",
        "    return mat[:n_rows, :n_columns]\n",
        "    \n",
        "\n",
        "def interpolate(array, delay, delay_matrix):\n",
        "    interp_matrix = tt.maximum(1-tt.abs_(delay_matrix - delay), 0)\n",
        "    interpolation = tt.dot(array,interp_matrix)\n",
        "    return interpolation\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgcFYhkCiDJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pymc3 as pm\n",
        "import theano.tensor as tt\n",
        "import theano\n",
        "import datetime\n",
        "import time\n",
        "\n",
        "\"\"\"\n",
        "Mahasedra comments:\n",
        "libraries and modules : pymc3 (on Bayesian statistical modeling),  \n",
        "theano (for manipulating and evaluating mathematical expressions, especially \n",
        "matrix-valued ones)\n",
        "\"\"\"\n",
        "\n",
        "date_data_begin = datetime.date(2020,4,1)\n",
        "date_data_end = datetime.date(2020,4,15)\n",
        "num_days_to_predict = 28\n",
        "\n",
        "\"\"\"\n",
        "Mahasedra:\n",
        "Above are the period of interest from which the data will be retrieved.\n",
        "\"\"\"\n",
        "\n",
        "diff_data_sim = 16 # should be significantly larger than the expected delay, in \n",
        "                   # order to always fit the same number of data points.\n",
        "\n",
        "\"\"\"\n",
        "Because of the reporting delay, in order to analyze the reported new cases \n",
        "between date_data_begin and date_data_end, we have to look at simulated/inferred\n",
        "values of new cases at time starting before t - delay.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "date_begin_sim = date_data_begin - datetime.timedelta(days = diff_data_sim)\n",
        "\n",
        "\"\"\"\n",
        "Mahasedra: (corrected)\n",
        "diff_data_sim: number of days which separate the date_data_begin (1 april 2020) \n",
        "and the date_begin_sim (1 2020: the simulation starts )\n",
        "\"\"\"\n",
        "format_date = lambda date_py: '{}/{}/{}'.format(date_py.month, date_py.day,\n",
        "                                                 str(date_py.year)[2:4])\n",
        "date_formatted_begin = format_date(date_data_begin)\n",
        "date_formatted_end = format_date(date_data_end)\n",
        "\n",
        "\"\"\"\n",
        "Mahasedra & Joely: format date\n",
        "\"\"\"\n",
        "\n",
        "cases_obs =  np.array(\n",
        "    csse_confirmed_cases.loc[csse_confirmed_cases[\"Country/Region\"] == \"Madagascar\", \n",
        "                        date_formatted_begin:date_formatted_end])[0]\n",
        "#cases_obs = np.concatenate([np.nan*np.ones(diff_data_sim), cases_obs])\n",
        "\n",
        "\"\"\"\n",
        "Mahasedra: (corrected)\n",
        "cases_obs : the number of infected cases in tana from the \n",
        "date_data_begin (1 march 2020) to the date_begin_sim (14 february 2020).\n",
        "\"\"\"\n",
        "\n",
        "print('Cases of ({}): {} and '\n",
        "      'day before that: {}'.format(date_data_end.isoformat(), *cases_obs[:-3:-1]))\n",
        "\n",
        "\"\"\"\n",
        "Mahasedra & Joely: output about the new cases at the begin day of \n",
        "the forecasting and at the day before.\n",
        "\"\"\"\n",
        "\n",
        "num_days = (date_data_end - date_begin_sim).days\n",
        "# \n",
        "date_today = date_data_end + datetime.timedelta(days=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uzw6ufc9iFsy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# ------------------------------------------------------------------------------ #\n",
        "# model setup and training\n",
        "# ------------------------------------------------------------------------------ #\n",
        "np.random.seed(0)\n",
        "\n",
        "def SIR_model(λ, μ, S_begin, I_begin, N):\n",
        "    new_I_0 = tt.zeros_like(I_begin)\n",
        "    def next_day(λ, S_t, I_t, _):\n",
        "        new_I_t = λ/N*I_t*S_t\n",
        "        S_t = S_t - new_I_t\n",
        "        I_t = I_t + new_I_t - μ * I_t\n",
        "        return S_t, I_t, new_I_t\n",
        "    outputs , _  = theano.scan(fn=next_day, sequences=[λ], \n",
        "                               outputs_info=[S_begin, I_begin, new_I_0])\n",
        "    S_all, I_all, new_I_all = outputs\n",
        "    return S_all, I_all, new_I_all\n",
        "\n",
        "    \"\"\"\n",
        "    Mahasedra:\n",
        "    SIR_model(): provides all values of S, I and new infected cases given\n",
        "    by the SIR model with the initial conditions S_begin, I_begin, N.\n",
        "    To be checked\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "with pm.Model() as model:\n",
        "    # true cases at begin of loaded data but we do not know the real number\n",
        "    I_begin = pm.HalfCauchy('I_begin', beta=100)\n",
        "\n",
        "    # fraction of people that are newly infected each day\n",
        "    λ = pm.Lognormal(\"λ\", mu=np.log(0.4), sigma=0.5)\n",
        "\n",
        "    # fraction of people that recover each day, recovery rate mu\n",
        "    μ = pm.Lognormal('μ', mu=np.log(1/8), sigma=0.2)\n",
        "\n",
        "    # delay in days between contracting the disease and being recorded\n",
        "    delay = pm.Lognormal(\"delay\", mu=np.log(8), sigma=0.2)\n",
        "\n",
        "    # prior of the error of observed cases\n",
        "    σ_obs = pm.HalfCauchy(\"σ_obs\", beta=10)\n",
        "\n",
        "    N_tana = 2e6\n",
        "\n",
        "    \"\"\"\n",
        "    Mahasedra & Joely: Prior distributions of the simple model's parameters \n",
        "    θ={λ, μ, D, σ,I0}\n",
        "    Mahasedra: I suppose that only part of the population can be really susceptible\n",
        "    to be infected.\n",
        "    \"\"\"\n",
        "\n",
        "    # -------------------------------------------------------------------------- #\n",
        "    # training the model with loaded data\n",
        "    # -------------------------------------------------------------------------- #\n",
        "\n",
        "    S_begin = N_tana - I_begin\n",
        "    S_past, I_past, new_I_past = SIR_model(λ=λ * tt.ones(num_days-1), μ=μ, \n",
        "                                               S_begin=S_begin, I_begin=I_begin,\n",
        "                                               N=N_tana)\n",
        "    new_cases_obs = np.diff(cases_obs)\n",
        "    new_cases_inferred = delay_cases(new_I_past, len_new_I_t=num_days - 1, \n",
        "                                     len_new_cases_obs=len(new_cases_obs), \n",
        "                                     delay=delay, delay_arr=diff_data_sim)\n",
        "\n",
        "    # Approximates Poisson\n",
        "    # calculate the likelihood of the model:\n",
        "    # observed cases are distributed following studentT around the model\n",
        "    pm.StudentT(\n",
        "        \"obs\",\n",
        "        nu=4,\n",
        "        mu=new_cases_inferred,\n",
        "        sigma=(new_cases_inferred)**0.5 * σ_obs,\n",
        "        observed=new_cases_obs)  \n",
        "    \n",
        "    S_past = pm.Deterministic('S_past', S_past)\n",
        "    I_past = pm.Deterministic('I_past', I_past)\n",
        "    new_I_past = pm.Deterministic('new_I_past', new_I_past)\n",
        "    new_cases_past = pm.Deterministic('new_cases_past', new_cases_inferred)\n",
        "\n",
        "    # -------------------------------------------------------------------------- #\n",
        "    # fp1 / prediction, start with no changes in policy\n",
        "    # red curve: no changes in policy\n",
        "    # transient = 0 day\n",
        "    # reduc_factor = 0\n",
        "    # no change in λ along time\n",
        "    # -------------------------------------------------------------------------- #\n",
        "\n",
        "    S_begin = S_past[-1]\n",
        "    I_begin = I_past[-1]\n",
        "    forecast_no_change = SIR_model(λ=λ*tt.ones(num_days_to_predict), μ=μ, \n",
        "                        S_begin=S_begin, I_begin=I_begin, N=N_tana)\n",
        "    S_no_change, I_no_change, new_I_no_change = forecast_no_change\n",
        "\n",
        "    #saves the variables for later retrieval\n",
        "    pm.Deterministic('S_no_change', S_no_change)\n",
        "    pm.Deterministic('I_no_change', I_no_change)\n",
        "    pm.Deterministic('new_I_no_change', new_I_no_change)\n",
        "\n",
        "    \"\"\"\n",
        "    PyMC3 allows you to freely do algebra with RVs in all kinds of ways (...).\n",
        "    While these transformations work seamlessly, their results are not \n",
        "    stored automatically. Thus, if you want to keep track of a transformed \n",
        "    variable, you have to use pm.Deterministic.\n",
        "    \"\"\"\n",
        "\n",
        "    new_cases_inferred = delay_cases(tt.concatenate([new_I_past[-diff_data_sim:], new_I_no_change]), \n",
        "                                     len_new_I_t=diff_data_sim + num_days_to_predict, \n",
        "                                     len_new_cases_obs=num_days_to_predict, \n",
        "                                     delay=delay, delay_arr=diff_data_sim)\n",
        "    pm.Deterministic('new_cases_no_change', new_cases_inferred)\n",
        "\n",
        "\n",
        "    # -------------------------------------------------------------------------- #\n",
        "    # fp2 / social distancing, m reduced by about 50 percent, \n",
        "    # orange curve: mild social distancing\n",
        "    # transient = 7 days\n",
        "    # reduc_factor = 0.5 (mild)\n",
        "    # change in λ along time\n",
        "    # days_offset = 0  i.e. start the decrease in spreading rate after this\n",
        "    # -------------------------------------------------------------------------- #\n",
        "    \n",
        "    #For all following predictions:\n",
        "    length_transient = 7  # days\n",
        "\n",
        "\n",
        "    # λ is decreased by 50%\n",
        "    reduc_factor_mild = 0.5\n",
        "    days_offset = 0  # start the decrease in spreading rate after this\n",
        "\n",
        "    time_arr = np.arange(num_days_to_predict)\n",
        "\n",
        "    # change in λ along time\n",
        "    λ_correction = tt.clip((time_arr - days_offset) / length_transient, 0, 1)\n",
        "    λ_t_soc_dist= λ * (1 - λ_correction * reduc_factor_mild) \n",
        "\n",
        "    S_begin = S_past[-1]\n",
        "    I_begin = I_past[-1]\n",
        "    forecast_soc_dist = SIR_model(λ=λ_t_soc_dist, μ=μ, \n",
        "                        S_begin=S_begin, I_begin=I_begin, \n",
        "                        N=N_tana)\n",
        "    S_soc_dist, I_soc_dist, new_I_soc_dist = forecast_soc_dist\n",
        "    pm.Deterministic('S_soc_dist', S_soc_dist)\n",
        "    pm.Deterministic('I_soc_dist', I_soc_dist)\n",
        "    pm.Deterministic('new_I_soc_dist', new_I_soc_dist)\n",
        "\n",
        "    new_cases_inferred = delay_cases(tt.concatenate([new_I_past[-diff_data_sim:], new_I_soc_dist]), \n",
        "                                    len_new_I_t=diff_data_sim + num_days_to_predict, \n",
        "                                    len_new_cases_obs=num_days_to_predict, \n",
        "                                    delay=delay, delay_arr=diff_data_sim)\n",
        "    pm.Deterministic('new_cases_soc_dist', new_cases_inferred)\n",
        "\n",
        "    # -------------------------------------------------------------------------- #\n",
        "    # fp3 / isolation, almost no new infections besides baseline after transient phase\n",
        "    # green curve : strong social distancing starting at day 0\n",
        "    # transient = 7 days\n",
        "    # reduc_factor = 0.9 (strong)\n",
        "    # change in λ along time\n",
        "    # days_offset = 0  \n",
        "    # -------------------------------------------------------------------------- #\n",
        "\n",
        "    # λ is decreased by 90%\n",
        "    reduc_factor_strong = 0.9\n",
        "    days_offset = 0  # start the decrease in spreading rate after this\n",
        "\n",
        "    # spreading of people who transmit although they are isolated\n",
        "    time_arr = np.arange(num_days_to_predict)\n",
        "\n",
        "    # change in λ along time\n",
        "    λ_correction = tt.clip((time_arr - days_offset) / length_transient, 0, 1)\n",
        "    λ_t_isol= λ * (1 - λ_correction * reduc_factor_strong)\n",
        "\n",
        "    S_begin = S_past[-1]\n",
        "    I_begin = I_past[-1]\n",
        "    forecast_isol = SIR_model(λ=λ_t_isol , μ=μ, \n",
        "                              S_begin=S_begin, I_begin=I_begin, \n",
        "                              N=N_tana)\n",
        "    S_isol, I_isol, new_I_isol = forecast_isol\n",
        "\n",
        "    pm.Deterministic('S_isol', S_isol)\n",
        "    pm.Deterministic('I_isol', I_isol)  \n",
        "    pm.Deterministic('new_I_isol', new_I_isol)\n",
        "\n",
        "    new_cases_inferred = delay_cases(tt.concatenate([new_I_past[-diff_data_sim:], new_I_isol]), \n",
        "                                len_new_I_t=diff_data_sim + num_days_to_predict, \n",
        "                                len_new_cases_obs=num_days_to_predict, \n",
        "                                delay=delay, delay_arr=diff_data_sim)\n",
        "    pm.Deterministic('new_cases_isol', new_cases_inferred)\n",
        "\n",
        "    # -------------------------------------------------------------------------- #\n",
        "    # fp4 / isolation 5 days later, almost no new infections besides baseline after transient phase\n",
        "    # fuchsia curve\n",
        "    # transient = 7 days\n",
        "    # reduc_factor = 0.9 (strong)\n",
        "    # change in λ along time\n",
        "    # days_offset = 5  \n",
        "    # -------------------------------------------------------------------------- #\n",
        "\n",
        "    # λ is decreased by 90%\n",
        "    reduc_factor_strong = 0.9\n",
        "    days_offset = 5  # start the decrease in spreading rate after this\n",
        "\n",
        "    # spreading of people who transmit although they are isolated\n",
        "    time_arr = np.arange(num_days_to_predict)\n",
        "\n",
        "    # change in λ along time\n",
        "    λ_correction = tt.clip((time_arr - days_offset) / length_transient, 0, 1)\n",
        "    λ_t_isol_later= λ * (1 - λ_correction * reduc_factor_strong) \n",
        "\n",
        "    S_begin = S_past[-1]\n",
        "    I_S_beginbegin = I_past[-1]\n",
        "    forecast_isol_later = SIR_model(λ=λ_t_isol_later, μ=μ, \n",
        "                         S_begin=S_begin, I_begin=I_begin, \n",
        "                         N=N_tana)\n",
        "    S_isol_later, I_isol_later, new_I_isol_later = forecast_isol_later\n",
        "\n",
        "    pm.Deterministic('S_isol_later', S_isol_later)\n",
        "    pm.Deterministic('I_isol_later', I_isol_later)  \n",
        "    pm.Deterministic('new_I_isol_later', new_I_isol_later)\n",
        "\n",
        "    new_cases_inferred = delay_cases(tt.concatenate([new_I_past[-diff_data_sim:], new_I_isol_later]), \n",
        "                            len_new_I_t=diff_data_sim + num_days_to_predict, \n",
        "                            len_new_cases_obs=num_days_to_predict, \n",
        "                            delay=delay, delay_arr=diff_data_sim)\n",
        "    pm.Deterministic('new_cases_isol_later', new_cases_inferred)\n",
        "\n",
        "\n",
        "    # -------------------------------------------------------------------------- #\n",
        "    # fp5 / isolation 5 days earlier, almost no new infections besides baseline after transient phase\n",
        "    # gray curve\n",
        "    # transient = 7 days\n",
        "    # reduc_factor = 0.9 (strong)\n",
        "    # change in λ along time\n",
        "    # days_offset = -5 (earlier)  \n",
        "    # -------------------------------------------------------------------------- #\n",
        "\n",
        "    length_transient = 7\n",
        "\n",
        "    # λ is decreased by 90%\n",
        "    reduc_factor = 0.9\n",
        "    days_offset = -5  # start the decrease in spreading rate after this\n",
        "\n",
        "    # spreading of people who transmit although they are isolated\n",
        "    time_arr = np.arange(days_offset, num_days_to_predict)\n",
        "\n",
        "    # change in λ along time\n",
        "\n",
        "    λ_t_earlier  = tt.clip((time_arr-days_offset) / length_transient, 0, 1)*\\\n",
        "                      (λ*(1-reduc_factor) - λ) + λ\n",
        "\n",
        "\n",
        "    S_begin = S_past[-1 + days_offset]\n",
        "    I_begin = I_past[-1 + days_offset]\n",
        "    forecast_earlier = SIR_model(λ=λ_t_earlier, μ=μ, \n",
        "                         S_begin=S_begin, I_begin=I_begin, \n",
        "                         N=N_tana)\n",
        "    S_earlier, I_earlier, new_I_earlier = forecast_earlier\n",
        "\n",
        "    pm.Deterministic('S_earlier', S_earlier)\n",
        "    pm.Deterministic('I_earlier', I_earlier)  \n",
        "    pm.Deterministic('new_I_earlier', new_I_earlier)\n",
        "    pm.Deterministic('λ_t_earlier', λ_t_earlier)\n",
        "\n",
        "\n",
        "    new_cases_inferred = delay_cases(tt.concatenate([new_I_past[-diff_data_sim:days_offset], new_I_earlier]), \n",
        "                            len_new_I_t=diff_data_sim + num_days_to_predict, \n",
        "                            len_new_cases_obs=num_days_to_predict, \n",
        "                            delay=delay, delay_arr=diff_data_sim)\n",
        "    \n",
        "    pm.Deterministic('new_cases_earlier', new_cases_inferred)\n",
        "\n",
        "\n",
        "    # -------------------------------------------------------------------------- #\n",
        "    # fp6 / long transient scenario  (cyan curve)\n",
        "    # transient = 14 days (long)\n",
        "    # reduc_factor = 0.9 (strong)\n",
        "    # change in λ along time\n",
        "    # days_offset = -3.5\n",
        "    # days_offset_sim = -4 \n",
        "    # -------------------------------------------------------------------------- #\n",
        "\n",
        "    length_transient = 14\n",
        "\n",
        "    # λ is decreased by 90%\n",
        "    reduc_factor = 0.9\n",
        "    days_offset = -3.5  # start the decrease in spreading rate after this\n",
        "    days_offset_sim = -4\n",
        "\n",
        "    # spreading of people who transmit although they are isolated\n",
        "    time_arr = np.arange(days_offset_sim, num_days_to_predict)\n",
        "\n",
        "    # change in λ along time\n",
        "\n",
        "    λ_t_long_trans  = tt.clip((time_arr-days_offset) / length_transient, 0, 1)*\\\n",
        "                      (λ*(1-reduc_factor) - λ) + λ\n",
        "\n",
        "\n",
        "    S_begin = S_past[-1 + days_offset_sim]\n",
        "    I_begin = I_past[-1 + days_offset_sim]\n",
        "    forecast_long_trans = SIR_model(λ=λ_t_long_trans, μ=μ, \n",
        "                         S_begin=S_begin, I_begin=I_begin, \n",
        "                         N=N_tana)\n",
        "    S_long_trans, I_long_trans, new_I_long_trans = forecast_long_trans\n",
        "\n",
        "    pm.Deterministic('S_long_trans', S_long_trans)\n",
        "    pm.Deterministic('I_long_trans', I_long_trans)  \n",
        "    pm.Deterministic('new_I_long_trans', new_I_long_trans)\n",
        "    pm.Deterministic('λ_t_long_trans', λ_t_long_trans)\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "    new_cases_inferred = delay_cases(tt.concatenate([new_I_past[-diff_data_sim:days_offset_sim], new_I_long_trans]), \n",
        "                            len_new_I_t=diff_data_sim + num_days_to_predict, \n",
        "                            len_new_cases_obs=num_days_to_predict, \n",
        "                            delay=delay, delay_arr=diff_data_sim)\n",
        "    pm.Deterministic('new_cases_long_trans', new_cases_inferred)\n",
        "\n",
        "\n",
        "    # -------------------------------------------------------------------------- #\n",
        "    # fp7 / immediate transient scenario (Brown curve)\n",
        "    # transient = 0.5 days\n",
        "    # reduc_factor = 0.9 (strong)\n",
        "    # change in λ along time\n",
        "    # days_offset = 3.5  \n",
        "    # -------------------------------------------------------------------------- #\n",
        "\n",
        "    # λ is decreased by 90%\n",
        "    reduc_factor_strong = 0.9\n",
        "    days_offset = 3.5 # start the decrease in spreading rate after this\n",
        "    length_transient = 0.5\n",
        "\n",
        "    # spreading of people who transmit although they are isolated\n",
        "    time_arr = np.arange(num_days_to_predict)\n",
        "\n",
        "    # change in λ along time\n",
        "    λ_correction = tt.clip((time_arr - days_offset) / length_transient, 0, 1)\n",
        "    λ_t_isol= λ * (1 - λ_correction * reduc_factor_strong)\n",
        "\n",
        "    S_begin = S_past[-1]\n",
        "    I_begin = I_past[-1]\n",
        "    forecast_isol = SIR_model(λ=λ_t_isol , μ=μ, \n",
        "                              S_begin=S_begin, I_begin=I_begin, \n",
        "                              N=N_tana)\n",
        "    S_isol, I_isol, new_I_isol = forecast_isol\n",
        "\n",
        "    pm.Deterministic('S_immedi', S_isol)\n",
        "    pm.Deterministic('I_immedi', I_isol)  \n",
        "    pm.Deterministic('new_immedi', new_I_isol)\n",
        "\n",
        "    new_cases_inferred = delay_cases(tt.concatenate([new_I_past[-diff_data_sim:], new_I_isol]), \n",
        "                                len_new_I_t=diff_data_sim + num_days_to_predict, \n",
        "                                len_new_cases_obs=num_days_to_predict, \n",
        "                                delay=delay, delay_arr=diff_data_sim)\n",
        "    pm.Deterministic('new_cases_immedi', new_cases_inferred)\n",
        "\n",
        "    # -------------------------------------------------------------------------- #\n",
        "    # run model, pm trains and predicts when calling this\n",
        "    # -------------------------------------------------------------------------- #\n",
        "    \n",
        "    time_beg = time.time()\n",
        "    trace = pm.sample(draws=3000, tune=800, chains=2)\n",
        "    print(\"Model run in {:.2f} s\".format(time.time() - time_beg))\n",
        "\n",
        "  #The number of effective samples is smaller than 25% for some parameters."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4RqAvlEiJsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(trace)\n",
        "type(trace)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lSEvdZ4iMZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "legends_lang = {\n",
        "    \"english\": [\n",
        "        # bottom left\n",
        "        \"Data nampiasana\",\n",
        "        [\n",
        "            \"Tsy misy ovaina ireo fepetra\",\n",
        "            \"Miha-enjana ireo fepetra\",\n",
        "            \"Tena miha-enjana ireo fepetra\",\n",
        "            \"Tena miha-henjana 5 andro lasa (10/03/20)\",\n",
        "        ],\n",
        "        \"Andro 0 (15/04/2020) sy ireo andro hafa\",\n",
        "        \"Totaly voa ao Madagascar\",\n",
        "        \"Fanombohan'ireo fepetra\",\n",
        "        # bottom right\n",
        "        'Data nampiasana',['Tena miha-henjana ireo fepetra:',\n",
        "                           '  manomboka andro 0', \n",
        "                           '  manomboka andro 0+5',\n",
        "                           \"  manomboka andro 0-5\"],\n",
        "        'Andro 0 (15/04/2020) sy ireo andro hafa',\n",
        "        'Totaly voa ao Madagascar',\n",
        "        \"Fanombohan'ireo fepetra\",\n",
        "        \"Taha-\\n pifindrana\",\n",
        "        ['Tena miha-henjana ireo fepetra',\n",
        "         'Tena miha-henjana ireo fepetra\\n  ary mihatra miadana ', \n",
        "         '  ary mihatra haingana'],\n",
        "    ],\n",
        "}\n",
        "\n",
        "#Legends\n",
        "\n",
        "obs_cases_labels = ['new_cases_no_change', 'new_cases_soc_dist', \n",
        "                    'new_cases_isol', 'new_cases_isol_later','new_cases_earlier', \n",
        "                    'new_cases_long_trans','new_cases_immedi']\n",
        "\n",
        "# label the variables related to the new_cases_inferred\n",
        "\n",
        "cases_obs_to_plot = np.array(csse_confirmed_cases.loc[csse_confirmed_cases['Country/Region'] == 'Madagascar', \n",
        "                                                 date_formatted_begin:date_formatted_end])[0]\n",
        "cases_obs_to_plot_future = np.array(csse_confirmed_cases.loc[csse_confirmed_cases['Country/Region'] == 'Madagascar', \n",
        "                                                        date_formatted_end:])[0]\n",
        "\n",
        "\n",
        "def return_obs_cases_future(trace):\n",
        "  obs_cases_future = dict()\n",
        "  for label in obs_cases_labels:\n",
        "    obs_cases_future[label] = np.cumsum(trace[label], axis=1) + \\\n",
        "        np.sum(trace.new_cases_past, axis=1)[:, None] + cases_obs[0]\n",
        "    obs_cases_future[label] = obs_cases_future[label].T\n",
        "  return obs_cases_future\n",
        "\n",
        "obs_cases_labels_local = obs_cases_labels[:]\n",
        "obs_cases_labels_local.pop(3)\n",
        "\n",
        "for lang, legends_list in legends_lang.items():\n",
        "    fig, axes = plt.subplots(nrows=2, ncols=3, figsize=[12, 6],gridspec_kw={'width_ratios': [1, 1,1]})\n",
        "\n",
        "    # bottom left (Fig. B2)\n",
        "    colors = [\"tab:red\", \"tab:orange\", \"tab:green\"]\n",
        "    dict_obsc_cases = return_obs_cases_future(trace)\n",
        "    ax = axes[1, 0]\n",
        "\n",
        "    # Below is about the confirmed cases\n",
        "\n",
        "    time = np.arange(-len(cases_obs_to_plot)+1, 1)\n",
        "    ax.plot(time, cases_obs_to_plot, label=legends_list[0], linewidth=3, color='tab:blue', \n",
        "                zorder=5)\n",
        "     \n",
        "    time = np.arange(0, len(cases_obs_to_plot_future))\n",
        "    #ax.plot(time, cases_obs_to_plot_future, '.', markersize=5, color='tab:blue', \n",
        "    #        zorder=5)\n",
        "\n",
        "    # above is about the confirmed cases\n",
        "\n",
        "    for label, color, legend in zip(obs_cases_labels_local, colors, legends_list[1]):\n",
        "        time = np.arange(0, num_days_to_predict)\n",
        "        cases = dict_obsc_cases[label]\n",
        "        # cases = np.concatenate([np.ones((1,cases.shape[1]))*cases_obs[-1], cases], axis=0)\n",
        "\n",
        "        median = np.median(cases, axis=-1)\n",
        "        percentiles = (\n",
        "            np.percentile(cases, q=2.5, axis=-1),\n",
        "            np.percentile(cases, q=97.5, axis=-1),\n",
        "        )\n",
        "        ax.plot(time, median, color, linewidth=3, label=legend)\n",
        "        ax.fill_between(time, percentiles[0], percentiles[1], alpha=0.08, color=color)\n",
        "\n",
        "    ax.set_xlim(-14, 21)\n",
        "    ax.set_ylim(0, 500)\n",
        "    ax.set_yscale(\"linear\")\n",
        "    ax.set_xlabel(legends_list[2])\n",
        "    ax.set_ylabel(legends_list[3])\n",
        "    # ax.locator_params(axis='y', nbins=4)\n",
        "    ax.legend(loc=\"upper left\")\n",
        "    ax.set_xticks([-14, -7, 0, 7, 14, 21])\n",
        "    ax.locator_params(nbins=4, axis=\"y\")\n",
        "    func_format = lambda num, _: \"${:,.0f}$\".format(num).replace(\",\", \"\\,\")\n",
        "    ax.yaxis.set_major_formatter(matplotlib.ticker.FuncFormatter(func_format))\n",
        "    ax.text(-0.3, 0.98, \"B2\", transform=ax.transAxes, size=20)\n",
        "\n",
        "    \n",
        "\n",
        "    ax.annotate(\n",
        "        legends_list[4],\n",
        "        xy=(0.0, 100), #\n",
        "        xycoords=\"data\",\n",
        "        xytext=(0.35, 0.4),\n",
        "        textcoords=\"axes fraction\",\n",
        "        size=10,\n",
        "        va=\"center\",\n",
        "        ha=\"center\",\n",
        "        arrowprops=dict(\n",
        "            arrowstyle=\"simple\", connectionstyle=\"arc3,rad=-0.2\", fc=\"black\"\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    # Above is Fig. B2\n",
        "\n",
        "    # bottom middle (Fig. D2)\n",
        "    ax = axes[1, 1]\n",
        "    colors = [\"tab:green\", \"fuchsia\", 'gray']\n",
        "    time = np.arange(-len(cases_obs_to_plot)+1, 1)\n",
        "    ax.plot(time, cases_obs_to_plot, label=legends_list[5], linewidth=3, color='tab:blue', \n",
        "                zorder=5)\n",
        "    time = np.arange(0, len(cases_obs_to_plot_future))\n",
        "    #ax.plot(time, cases_obs_to_plot_future, '.', markersize=5, color='tab:blue', \n",
        "    #        zorder=5)\n",
        "    time = np.arange(-len(cases_obs) + 1, 1)\n",
        "\n",
        "    dict_obsc_cases = return_obs_cases_future(trace)\n",
        "    ax.plot([], [], alpha=0, label=legends_list[6][0])\n",
        "    for label, color, legend in zip(obs_cases_labels[2:], colors, legends_list[6][1:]):\n",
        "        time = np.arange(num_days_to_predict)\n",
        "        cases = dict_obsc_cases[label]\n",
        "        #cases = np.concatenate([np.ones((1, cases.shape[1])) * cases_obs[-1], cases], axis=0)\n",
        "        median = np.median(cases, axis=-1)\n",
        "        percentiles = (\n",
        "            np.percentile(cases, q=2.5, axis=-1),\n",
        "            np.percentile(cases, q=97.5, axis=-1),\n",
        "        )\n",
        "        ax.plot(time, median, color, linewidth=3, label=legend)\n",
        "        ax.fill_between(time, percentiles[0], percentiles[1], alpha=0.08, color=color)\n",
        "\n",
        "    ax.set_xlim(-14, 21)\n",
        "    ax.set_ylim(0, 500)\n",
        "    ax.set_yscale(\"linear\")\n",
        "    ax.set_xlabel(legends_list[7])\n",
        "    #ax.set_ylabel(legends_list[8])\n",
        "    ax.locator_params(axis=\"y\", nbins=4)\n",
        "    ax.legend(loc=\"upper left\")\n",
        "    ax.set_xticks([-14, -7, 0, 7, 14, 21])\n",
        "    #func_format = lambda num, _: \"${:,.0f}$\".format(num).replace(\",\", \"\\,\")\n",
        "    #ax.yaxis.set_major_formatter(matplotlib.ticker.FuncFormatter(func_format))\n",
        "    ax.tick_params(labelleft=False)    \n",
        "\n",
        "    ax.text(-0.1, 0.98, \"D2\", transform=ax.transAxes, size=20)\n",
        "\n",
        "    ax.annotate(\n",
        "        legends_list[9],\n",
        "        xy=(0.0, 100),\n",
        "        xycoords=\"data\",\n",
        "        xytext=(0.35, 0.4),\n",
        "        textcoords=\"axes fraction\",\n",
        "        size=10,\n",
        "        va=\"center\",\n",
        "        ha=\"center\",\n",
        "        arrowprops=dict(\n",
        "            arrowstyle=\"simple\", connectionstyle=\"arc3,rad=-0.15\", fc=colors[0]\n",
        "        ),\n",
        "    )\n",
        "    ax.annotate(\n",
        "        \"\",\n",
        "        xy=(5.0, 120),\n",
        "        xycoords=\"data\",\n",
        "        xytext=(0.4, 0.35),\n",
        "        textcoords=\"axes fraction\",\n",
        "        size=10,\n",
        "        va=\"center\",\n",
        "        ha=\"center\",\n",
        "        arrowprops=dict(\n",
        "            arrowstyle=\"simple\", connectionstyle=\"arc3,rad=-0.2\", fc=colors[1]\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    ax.annotate(\n",
        "        \"\",\n",
        "        xy=(-5.0, 100),\n",
        "        xycoords=\"data\",\n",
        "        xytext=(0.32, 0.35),\n",
        "        textcoords=\"axes fraction\",\n",
        "        size=14,\n",
        "        va=\"center\",\n",
        "        ha=\"center\",\n",
        "        arrowprops=dict(\n",
        "            arrowstyle=\"simple\", connectionstyle=\"arc3,rad=-0.2\", fc=colors[2]\n",
        "        ),\n",
        "    )\n",
        "    # Above is Fig. D2\n",
        "\n",
        "    # bottom right (Fig. F2)\n",
        "    ax = axes[1, 2]\n",
        "    colors = [\"tab:green\", \"tab:cyan\", 'tab:brown']\n",
        "    time = np.arange(-len(cases_obs_to_plot)+1, 1)\n",
        "    ax.plot(time, cases_obs_to_plot, label=legends_list[5], linewidth=3, color='tab:blue', \n",
        "                zorder=5)\n",
        "    time = np.arange(0, len(cases_obs_to_plot_future))\n",
        "    #ax.plot(time, cases_obs_to_plot_future, '.', markersize=5, color='tab:blue', \n",
        "    #        zorder=5)\n",
        "    time = np.arange(-len(cases_obs) + 1, 1)\n",
        "\n",
        "    dict_obsc_cases = return_obs_cases_future(trace)\n",
        "    for label, color, legend in zip([obs_cases_labels[2], obs_cases_labels[-1], obs_cases_labels[-2]], \n",
        "                                    colors, legends_list[11]):\n",
        "        time = np.arange(num_days_to_predict)\n",
        "        cases = dict_obsc_cases[label]\n",
        "        #cases = np.concatenate([np.ones((1, cases.shape[1])) * cases_obs[-1], cases], axis=0)\n",
        "        median = np.median(cases, axis=-1)\n",
        "        percentiles = (\n",
        "            np.percentile(cases, q=2.5, axis=-1),\n",
        "            np.percentile(cases, q=97.5, axis=-1),\n",
        "        )\n",
        "        ax.plot(time, median, color, linewidth=3, label=legend)\n",
        "        ax.fill_between(time, percentiles[0], percentiles[1], alpha=0.08, color=color)\n",
        "\n",
        "    ax.set_xlim(-14, 21)\n",
        "    ax.set_ylim(0, 500)\n",
        "    ax.set_yscale(\"linear\")\n",
        "    ax.set_xlabel(legends_list[7])\n",
        "    #ax.set_ylabel(legends_list[8])\n",
        "    ax.locator_params(axis=\"y\", nbins=4)\n",
        "    ax.legend(loc=\"upper left\")\n",
        "    ax.set_xticks([-14, -7, 0, 7, 14, 21])\n",
        "    #func_format = lambda num, _: \"${:,.0f}$\".format(num).replace(\",\", \"\\,\")\n",
        "    #ax.yaxis.set_major_formatter(matplotlib.ticker.FuncFormatter(func_format))\n",
        "    ax.tick_params(labelleft=False)    \n",
        "\n",
        "    ax.text(-0.1, 0.98, \"F2\", transform=ax.transAxes, size=20)\n",
        "\n",
        "    # Above is Fig.F2\n",
        "\n",
        "    # top left (Fig. A2)\n",
        "    ax = axes[0, 0]\n",
        "\n",
        "    m = np.median(trace.λ)\n",
        "    decrease_in = 7  # days\n",
        "    time = np.arange(-14, 22)\n",
        "    m_correction = np.clip(time / decrease_in, 0, 1)\n",
        "    reduction_fact_strong = 0.9\n",
        "    reduction_fact_mild = 0.5\n",
        "\n",
        "    ax.plot(time, np.ones_like(time)*m, linewidth=3, color=\"tab:red\")\n",
        "    ax.plot(\n",
        "        time,\n",
        "        (1 - m_correction * reduction_fact_mild)*m,\n",
        "        linewidth=3,\n",
        "        color=\"tab:orange\" )\n",
        "    ax.plot(\n",
        "        time,\n",
        "        (1 - m_correction * reduction_fact_strong)*m,\n",
        "        linewidth=3,\n",
        "        color=\"tab:green\" )\n",
        "    ax.hlines(np.median(trace.μ),-50,50, linestyles=':',label='critical point')\n",
        "    #ax.legend()\n",
        "\n",
        "    ax.set_ylabel(legends_list[10])\n",
        "    # ax.set_xlabel(\"days from now\")\n",
        "    # ax.legend(loc='lower left')\n",
        "    ax.set_xticks([-14, -7, 0, 7, 14, 21])\n",
        "    ax.set_ylim(0, 0.3)\n",
        "    ax.set_yticks([0, 0.1, 0.2])\n",
        "    ax.set_xlim(-14, 21)\n",
        "    ax.set_aspect(14, adjustable=\"box\")\n",
        "    ax.text(-0.3, 0.98, \"A2\", transform=ax.transAxes, size=20)\n",
        "    ax.text(-11, 0.2, \"$\\mu$\", transform=ax.transData, size=10)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['top'].set_visible(False)\n",
        "\n",
        "    # Above is Fig. A2\n",
        "\n",
        "    # top middle (Fig. C2)\n",
        "    ax = axes[0, 1]\n",
        "\n",
        "    m = np.median(trace.λ)\n",
        "    length_transient = 7  # days\n",
        "    time = np.arange(-14, 22)\n",
        "    \n",
        "    reduc_factor_mild = 0.9\n",
        "    days_offset_mild = -5  # start the decrease in spreading rate after this\n",
        "    reduc_factor_strong = 0.9\n",
        "    days_offset_strong = 5\n",
        "\n",
        "    # spreading of people who transmit although they are isolated\n",
        "    time_arr = np.arange(num_days_to_predict)\n",
        "\n",
        "    # change in λ along time\n",
        "    λ_t1  = np.clip((time-days_offset_mild) / length_transient, 0, 1)*\\\n",
        "                      (m*(1-reduc_factor_mild) - m)+m\n",
        "    λ_t2  = np.clip((time-days_offset_strong) / length_transient, 0, 1)*\\\n",
        "                      (m*(1-reduc_factor_strong) - m)+m\n",
        "\n",
        "    #ax.plot(time, np.ones_like(time), linewidth=3, color=\"tab:red\", label=\"no change\")\n",
        "    \n",
        "    ax.plot(\n",
        "        time,\n",
        "        (λ_t2),\n",
        "        linewidth=3,\n",
        "        color=\"fuchsia\",\n",
        "    )\n",
        "    ax.plot(\n",
        "        time,\n",
        "        (λ_t1),\n",
        "        linewidth=3,\n",
        "        color=\"gray\",\n",
        "    )\n",
        "    ax.plot(\n",
        "        time,\n",
        "        (1 - m_correction * reduction_fact_strong)*m,\n",
        "        linewidth=3,\n",
        "        color=\"tab:green\",\n",
        "    )\n",
        "    ax.hlines(np.median(trace.μ),-50,50, linestyles=':',label='critical point')\n",
        "    #ax.legend()\n",
        "\n",
        "    #ax.set_ylabel(legends_list[10])\n",
        "    # ax.set_xlabel(\"days from now\")\n",
        "    # ax.legend(loc='lower left')\n",
        "    ax.set_xticks([-14, -7, 0, 7, 14, 21])\n",
        "    #ax.set_yticks([0, 0.5, 1.0])\n",
        "    ax.set_yticks([0, 0.1, 0.2])\n",
        "    ax.tick_params(labelleft=False)    \n",
        "    ax.set_ylim(0, 0.3)\n",
        "    ax.set_xlim(-14, 21)\n",
        "    ax.set_aspect(14, adjustable=\"box\")\n",
        "    ax.text(-0.1, 0.98, \"C2\", transform=ax.transAxes, size=20)\n",
        "    ax.text(-11, 0.2, \"$\\mu$\", transform=ax.transData, size=10)\n",
        "\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['top'].set_visible(False)\n",
        "\n",
        "    # top right (Fig. E2)\n",
        "    ax = axes[0, 2]\n",
        "\n",
        "    m = np.median(trace.λ)\n",
        "    length_transient1 = 14  # days\n",
        "    length_transient2 = 0.5\n",
        "    time = np.arange(-14, 22)\n",
        "    reduc_factor_mild = 0.9\n",
        "    days_offset_mild = -3.5  # start the decrease in spreading rate after this\n",
        "\n",
        "    reduc_factor_strong = 0.9\n",
        "    days_offset_strong = 3.5\n",
        "\n",
        "    # spreading of people who transmit although they are isolated\n",
        "    time_arr = np.arange(num_days_to_predict)\n",
        "\n",
        "    # change in λ along time\n",
        "    λ_t1  = np.clip((time-days_offset_mild) / length_transient1, 0, 1)*\\\n",
        "                      (m*(1-reduc_factor_mild) - m)+m\n",
        "    λ_t2  = np.clip((time-days_offset_strong) / length_transient2, 0, 1)*\\\n",
        "                      (m*(1-reduc_factor_strong) - m)+m\n",
        "\n",
        "    #ax.plot(time, np.ones_like(time), linewidth=3, color=\"tab:red\", label=\"no change\")\n",
        "    \n",
        "    ax.plot(\n",
        "        time,\n",
        "        λ_t2,\n",
        "        linewidth=3,\n",
        "        color=\"tab:brown\",\n",
        "    )\n",
        "    ax.plot(\n",
        "        time,\n",
        "        (λ_t1),\n",
        "        linewidth=3,\n",
        "        color=\"tab:cyan\",\n",
        "    )\n",
        "    ax.plot(\n",
        "        time,\n",
        "        (1 - m_correction * reduction_fact_strong)*m,\n",
        "        linewidth=3,\n",
        "        color=\"tab:green\",\n",
        "    )\n",
        "\n",
        "    ax.hlines(np.median(trace.μ),-50,50, linestyles=':',label='critical point')\n",
        "    #ax.legend()\n",
        "\n",
        "    #ax.set_ylabel(legends_list[10])\n",
        "    # ax.set_xlabel(\"days from now\")\n",
        "    # ax.legend(loc='lower left')\n",
        "    ax.set_xticks([-14, -7, 0, 7, 14, 21])\n",
        "    ax.set_yticks([0, 0.1, 0.2])\n",
        "    ax.tick_params(labelleft=False)    \n",
        "    ax.set_ylim(0, 0.2)\n",
        "    ax.set_xlim(-14, 21)\n",
        "    ax.set_aspect(14, adjustable=\"box\")\n",
        "    ax.text(-0.1, 0.98, \"E2\", transform=ax.transAxes, size=20)\n",
        "    ax.text(-11, 0.2, \"$\\mu$\", transform=ax.transData, size=10)\n",
        "\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    # Above is Fig. E2.\n",
        "\n",
        "\n",
        "    # wrapping up\n",
        "    fig.subplots_adjust(hspace=-0.50)\n",
        "    fig.subplots_adjust(wspace=-.1)\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(\n",
        "        path_to_save + \"sar2cssemdg.png\".format(lang), dpi=300\n",
        "    )\n",
        "    fig.savefig(path_to_save + \"sar2cssemdg.pdf\")\n",
        "\n",
        "print('effective m: {:.3f} +- {:.3f}'.format(1+np.median(trace.λ - trace.μ), np.std(trace.λ - trace.μ)))\n",
        "print('λ: {:.3f} [{:.3f}, {:.3f}]'.format(np.median(trace.λ), *np.percentile(trace.λ, q=(2.5, 97.5))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAyhmBU9iVr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def truncate_number(number, precision):\n",
        "    number = round(number, ndigits = precision)\n",
        "    #number = round(number - number%(10**(-precision)),10)\n",
        "    if precision == 0:\n",
        "        number = int(round(number))\n",
        "    return str(number)\n",
        "\n",
        "def print_median_CI(arr, prec = 2):\n",
        "    f_trunc = lambda n: truncate_number(n, prec)\n",
        "    med = f_trunc(np.median(arr))\n",
        "    perc1, perc2 = f_trunc(np.percentile(arr, q=2.5)), f_trunc(np.percentile(arr, q=97.5))\n",
        "    #print('The 95% CI of {} is [{:.3f} , {:.3f}] with a median of {:.3f}'.format(label, med, perc1, perc2))\n",
        "    return 'median: {}\\nCI: [{}, {}]'.format(med, perc1, perc2)\n",
        "\n",
        "def conv_time_to_mpl_dates(arr):\n",
        "    return matplotlib.dates.date2num([datetime.timedelta(days=float(date)) + date_data_end for date in arr])\n",
        "\n",
        "#Definitions\n",
        "letter_size = 15\n",
        "ci_location = [0.95,0.9]\n",
        "alpha_texbox = 0.3\n",
        "font_text = 10\n",
        "\n",
        "#Making all square for simplicity\n",
        "len1 = 5\n",
        "len2 = 3\n",
        "\n",
        "fig = plt.figure(figsize=(8.5,8.5),constrained_layout=True)\n",
        "gs = fig.add_gridspec(15,11)\n",
        "\n",
        "ax_cases_new = fig.add_subplot(gs[0:len1,0:len1])\n",
        "ax_cases_total = fig.add_subplot(gs[len1:2*len1,0:len1])\n",
        "ax_error = fig.add_subplot(gs[2*len1:3*len1,0:len1])\n",
        "\n",
        "ax_param_infection  = fig.add_subplot(gs[0:len2,len1:len1+len2])\n",
        "ax_param_recovery = fig.add_subplot(gs[0:len2,len1+len2:len1+2*len2])\n",
        "\n",
        "ax_param_izero = fig.add_subplot(gs[len2:2*len2,len1:len1+len2])\n",
        "ax_param_delay = fig.add_subplot(gs[len2:2*len2,len1+len2:len1+2*len2])\n",
        "\n",
        "ax_param_width = fig.add_subplot(gs[2*len2:3*len2,len1:len1+len2])\n",
        "ax_param_effective_rate = fig.add_subplot(gs[2*len2:3*len2,len1+len2:len1+2*len2])\n",
        "\n",
        "ax_likelihood = fig.add_subplot(gs[3*len2:3*len1,len1:len1+2*len2])\n",
        "\n",
        "#manomboka eto Sar. A1\n",
        "\n",
        "#Plots things\n",
        "pos_letter = (-0.2, 1.05)\n",
        "\n",
        "ax = ax_cases_new\n",
        "time = np.arange(-len(cases_obs)+1, 0)\n",
        "mpl_dates = conv_time_to_mpl_dates(time) \n",
        "start_date, end_date = mpl_dates[0], mpl_dates[-1]\n",
        "ax.plot(mpl_dates, np.diff(cases_obs), 'd', markersize=6, label='Data')\n",
        "percentiles = np.percentile(trace.new_cases_past, q=2.5, axis=0), np.percentile(trace.new_cases_past, q=97.5, axis=0)\n",
        "ax.plot(mpl_dates, np.median(trace.new_cases_past, axis=0),color='tab:orange', label='Fit (with 95% CI)', lw=3)\n",
        "ax.fill_between(mpl_dates, percentiles[0], percentiles[1], alpha=0.3, color='tab:orange')\n",
        "ax.set_yscale('log')\n",
        "ax.set_ylabel(\" Isan'ireo voa vaovao\")\n",
        "ax.set_xlabel('Daty')\n",
        "ax.legend()\n",
        "ax.text(pos_letter[0], pos_letter[1], \"A1\", transform=ax.transAxes, size=letter_size)\n",
        "#mifarana eto Sar. A1\n",
        "\n",
        "#manomboka eto Sar. B1\n",
        "ax.xaxis.set_major_locator(matplotlib.dates.AutoDateLocator())\n",
        "ax.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%-m/%-d'))\n",
        "ax.set_xlim(start_date, end_date)\n",
        "\n",
        "ax = ax_cases_total\n",
        "ax.plot(mpl_dates, cases_obs[1:], 'd', markersize=6, label='Data')\n",
        "cum_cases = np.cumsum(trace.new_cases_past, axis=1) + cases_obs[0]\n",
        "percentiles = np.percentile(cum_cases, q=2.5, axis=0), np.percentile(cum_cases, q=97.5, axis=0)\n",
        "ax.plot(mpl_dates, np.median(cum_cases, axis=0),color='tab:orange', label='Fit (with 95% CI)', lw=3)\n",
        "ax.fill_between(mpl_dates, percentiles[0], percentiles[1], alpha=0.3, color='tab:orange')\n",
        "ax.set_yscale('log')\n",
        "ax.set_ylabel(\"Isan'ireo voa rehetra\")\n",
        "ax.set_xlabel('Daty')\n",
        "#ax.legend()\n",
        "ax.text(pos_letter[0], pos_letter[1], \"B1\", transform=ax.transAxes, size=letter_size)\n",
        "#mifarana eto Sar. B1\n",
        "\n",
        "#manomboka eto Sar. C1\n",
        "ax.xaxis.set_major_locator(matplotlib.dates.AutoDateLocator())\n",
        "ax.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%-m/%-d'))\n",
        "ax.set_xlim(start_date, end_date)\n",
        "\n",
        "ax = ax_error\n",
        "ax.plot(mpl_dates, np.abs(np.median(trace.new_cases_past, axis=0) - np.diff(cases_obs)), \n",
        "        'd', markersize=6,\n",
        "         label='Elanelana\\n'\n",
        "               'fity (fit) sy data')\n",
        "ax.plot(mpl_dates, np.sqrt(np.median(trace.new_cases_past, axis=0))*np.median(trace.σ_obs, axis=0),\n",
        "         label='Width of the likelihood', lw=3)\n",
        "ax.set_ylabel(\"Elanelana\\n(isan'ireo voa vaovao)\")\n",
        "ax.set_xlabel('Daty')\n",
        "ax.legend(loc='upper left')\n",
        "print(np.median(np.sum(trace.new_cases_past[:, :-2], axis=1)+ trace.I_begin))\n",
        "ax.text(pos_letter[0], pos_letter[1], \"C1\", transform=ax.transAxes, size=letter_size)\n",
        "#plt.tight_layout()\n",
        "\n",
        "#mifarana eto Sar. C1\n",
        "\n",
        "#manomboka eto Sar. D1\n",
        "ax.xaxis.set_major_locator(matplotlib.dates.AutoDateLocator())\n",
        "ax.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%-m/%-d'))\n",
        "ax.set_xlim(start_date, end_date)\n",
        "plt.savefig(path_to_save + 'check_fit_composed.png', dpi=300)\n",
        "ax = ax_param_infection\n",
        "ax.hist(trace.λ, bins=50, density=True, color='tab:orange',\n",
        "        label='Posterior')\n",
        "limits = ax.get_xlim()\n",
        "x = np.linspace(*limits, num=100)\n",
        "ax.plot(x, scipy.stats.lognorm.pdf(x, scale=0.4, s=0.5), label='Prior',\n",
        "        color=\"#708090\", linewidth=3)\n",
        "ax.set_xlim(*limits)\n",
        "ax.set_ylabel('Density')\n",
        "ax.set_xlabel('Taha $\\lambda$')\n",
        "text = print_median_CI(trace.λ, prec=2)\n",
        "ax.text(ci_location[0], ci_location[1], text, horizontalalignment='right',\n",
        "      verticalalignment='top', transform=ax.transAxes,  bbox=dict(facecolor='white', alpha=alpha_texbox,edgecolor='none'),fontsize=font_text)\n",
        "ax.text(pos_letter[0], pos_letter[1], \"D1\", transform=ax.transAxes, size=letter_size)\n",
        "#ax.legend(loc='upper right')\n",
        "\n",
        "#mifarana eto Sar. D1\n",
        "\n",
        "# manomboka eto Sar. E1\n",
        "ax = ax_param_recovery\n",
        "ax.hist(trace.μ, bins=50, density=True, color='tab:orange',\n",
        "        label='Posterior')\n",
        "limits = ax.get_xlim()\n",
        "x = np.linspace(*limits, num=100)\n",
        "ax.plot(x, scipy.stats.lognorm.pdf(x, scale=1/8, s=0.2), label='Prior',\n",
        "        color=\"#708090\", linewidth=3)\n",
        "ax.set_xlim(*limits)\n",
        "ax.set_ylabel('Density')\n",
        "ax.set_xlabel('Taha $\\mu$')\n",
        "text = print_median_CI(trace.μ, prec=2)\n",
        "ax.text(ci_location[0], ci_location[1], text, horizontalalignment='right',\n",
        "      verticalalignment='top', transform=ax.transAxes,  bbox=dict(facecolor='white', alpha=alpha_texbox,edgecolor='none'),fontsize=font_text)\n",
        "ax.text(pos_letter[0], pos_letter[1], \"E1\", transform=ax.transAxes, size=letter_size)\n",
        "#ax.legend(loc='upper right')\n",
        "\n",
        "#mifarana eto Sar. E1\n",
        "\n",
        "#manomboka eto Sar. G1\n",
        "ax = ax_param_effective_rate\n",
        "ax.locator_params(nbins=5)\n",
        "#bins = np.linspace(-0.11, 0.304, 200)\n",
        "ax.hist((trace.λ - trace.μ)*100, bins=50, color='tab:orange')\n",
        "ax.set_xlabel('Taha $\\lambda^* = \\lambda - \\mu$ (%)')#\\n'\n",
        "          #'inferred from data - from {} to {}'.format(date_data_begin.isoformat(), \n",
        "          #                                            date_data_end.isoformat()))\n",
        "ax.set_ylabel('Number of Monte-Carlo samples')\n",
        "text = print_median_CI((trace.λ - trace.μ)*100, prec=0)\n",
        "ax.text(ci_location[0], ci_location[1], text, horizontalalignment='right',\n",
        "      verticalalignment='top', transform=ax.transAxes,  bbox=dict(facecolor='white', alpha=alpha_texbox,edgecolor='none'),fontsize=font_text)\n",
        "ax.text(pos_letter[0], pos_letter[1], \"I1\", transform=ax.transAxes, size=letter_size)\n",
        "#mifarana eto Sar. I1\n",
        "\n",
        "#manomboka eto Sar. G1\n",
        "ax = ax_param_delay\n",
        "ax.hist(trace.delay, bins=50, density=True, color='tab:orange',\n",
        "        label='Posterior')\n",
        "limits = ax.get_xlim()\n",
        "x = np.linspace(*limits, num=100)\n",
        "ax.plot(x, scipy.stats.lognorm.pdf(x, scale=8, s=0.2), label='Prior',\n",
        "        color=\"#708090\", linewidth=3)\n",
        "ax.set_xlim(*limits)\n",
        "ax.set_ylabel('Density')\n",
        "ax.set_xlabel('Fahatarana $D$')\n",
        "text = print_median_CI(trace.delay, prec=1)\n",
        "ax.text(ci_location[0], ci_location[1], text, horizontalalignment='right',\n",
        "      verticalalignment='top', transform=ax.transAxes,  bbox=dict(facecolor='white', alpha=alpha_texbox,edgecolor='none'),fontsize=font_text)\n",
        "#ax.legend(loc='upper right')\n",
        "ax.text(pos_letter[0], pos_letter[1], \"G1\", transform=ax.transAxes, size=letter_size)\n",
        "\n",
        "#mifarana eto Sar. G1\n",
        "\n",
        "#manomboka eto Sar. H1\n",
        "ax = ax_param_width\n",
        "ax.hist(trace.σ_obs, bins=50, color='tab:orange', density=True, label='Posterior')\n",
        "ax.set_ylabel('Density')\n",
        "ax.set_xlabel(\" $\\sigma$ (likelihood)\")\n",
        "limits = ax.get_xlim()\n",
        "x = np.linspace(*limits, num=100)\n",
        "ax.plot(x, scipy.stats.halfcauchy.pdf(x, scale=10), label='Prior',\n",
        "        color=\"#708090\", linewidth=3)\n",
        "ax.set_xlim(*limits)\n",
        "text = print_median_CI(trace.σ_obs, prec=1)\n",
        "ax.text(ci_location[0], ci_location[1], text, horizontalalignment='right',\n",
        "      verticalalignment='top', transform=ax.transAxes,  bbox=dict(facecolor='white', alpha=alpha_texbox,edgecolor='none'),fontsize=font_text)\n",
        "#ax.legend(loc='upper right')\n",
        "ax.text(pos_letter[0], pos_letter[1], \"H1\", transform=ax.transAxes, size=letter_size)\n",
        "\n",
        "#mifarana eto Sar. H1\n",
        "\n",
        "#manomboka eto Sar. F1\n",
        "ax = ax_param_izero\n",
        "ax.hist(trace.I_begin, bins=50, color='tab:orange', density=True, label='Posterior')\n",
        "ax.set_ylabel('Density')\n",
        "ax.set_xlabel(\"Voa rehetra $I_0$\")\n",
        "limits = ax.get_xlim()\n",
        "x = np.linspace(*limits, num=5000)\n",
        "ax.plot(x, scipy.stats.halfcauchy.pdf(x, scale=100), label='Prior',\n",
        "        color=\"#708090\", linewidth=3)\n",
        "ax.set_xlim(*limits)\n",
        "ax.set_xlim(0)\n",
        "text = print_median_CI(trace.I_begin, prec=0)\n",
        "ax.text(ci_location[0], ci_location[1], text, horizontalalignment='right',\n",
        "      verticalalignment='top', transform=ax.transAxes,  bbox=dict(facecolor='white', alpha=alpha_texbox,edgecolor='none'),fontsize=font_text)\n",
        "ax.legend(loc='lower right')\n",
        "ax.text(pos_letter[0], pos_letter[1], \"F1\", transform=ax.transAxes, size=letter_size)\n",
        "\n",
        "#mifarana eto Sar. F1\n",
        "\n",
        "# manomboka eto Sar. J1\n",
        "ax = ax_likelihood\n",
        "ax.locator_params(nbins=5)\n",
        "μ_arr = np.linspace(0.02, 0.3, 25)\n",
        "#λ_arr = np.linspace(0.2, 0.6, 25)\n",
        "matrix = pickle.load(open(path_data + 'likelihood_matrix.pickled', 'rb'))\n",
        "#matrix has [i,j] = [lambda,mu] with i rows -> rows for imshow are y\n",
        "#so mu is on x axis...as we want to\n",
        "im_mat = []\n",
        "print(matrix.shape)\n",
        "for row in matrix:\n",
        "    im_mat.append([])\n",
        "    for elem in row:\n",
        "        if elem is not None:\n",
        "            im_mat[-1].append(elem['logp'])\n",
        "        else: im_mat[-1].append(np.nan)\n",
        "#fig, ax1 = plt.subplots(1,1)\n",
        "#im = ax1.imshow(im_mat, origin='lower', extent=[0.02, 0.3, 0.2, 0.6], aspect=0.5)\n",
        "#plt.colorbar()\n",
        "#heatmap = ax.imshow(im_mat, origin='lower', extent=[0.02, 0.3, 0.2, 0.6], aspect=0.71)\n",
        "#heatmap = ax.imshow(im_mat, origin='lower', extent=[0.02, 0.3, 0.2, 0.6])\n",
        "heatmap = ax.imshow(im_mat,origin='lower',extent=[0.02, 0.3, 0.2, 0.6], aspect='auto')\n",
        "pos = ax.get_position()\n",
        "#cbaxes = fig.add_axes([0.43, pos.y0, 0.02, pos.y1-pos.y0])\n",
        "#cbar = fig.colorbar(heatmap, cbaxes)\n",
        "#cbar.set_label('log-likelihood')\n",
        "ax.plot(μ_arr, μ_arr+0.30, color='black')\n",
        "cbar = plt.colorbar(heatmap)\n",
        "cbar.set_label('log-likelihood')\n",
        "ax.set_ylabel('taha $\\lambda$')\n",
        "ax.set_xlabel('taha $\\mu$')\n",
        "ax.text(pos_letter[0], pos_letter[1], \"J1\", transform=ax.transAxes, size=letter_size)\n",
        "#ax.set_anchor('NW')\n",
        "\n",
        "#Removes ylabels from D-I\n",
        "ax_params = [ax_param_infection,ax_param_recovery, ax_param_effective_rate, ax_param_delay,ax_param_width,ax_param_izero]\n",
        "for ax in ax_params:\n",
        "  ax.set_yticks([], [])\n",
        "  ax.set_ylabel('')\n",
        "\n",
        "#gs.update(wspace=0.9, hspace=0.9)\n",
        "#gs.update()\n",
        "#plt.tight_layout()\n",
        "\n",
        "plt.savefig(path_to_save+'sar1cssemdg.png')\n",
        "plt.savefig(path_to_save+'sar1cssemdg.pdf')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}